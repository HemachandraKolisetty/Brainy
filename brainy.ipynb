{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45607155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "root_folder = \"./tactile_dataset/\"\n",
    "\n",
    "velocities = [30]\n",
    "\n",
    "num_textures = 12\n",
    "texture_names = [f\"texture_{i:02d}\" for i in range(1, num_textures + 1)]\n",
    "\n",
    "def load_and_merge_data(root, velocity, texture):\n",
    "    velocity_folder = os.path.join(root, f\"pickles_{velocity}\")\n",
    "    texture_folder = os.path.join(velocity_folder, texture)\n",
    "    \n",
    "    baro_file = os.path.join(texture_folder, \"full_baro.csv\")\n",
    "    imu_file = os.path.join(texture_folder, \"full_imu.csv\")\n",
    "    \n",
    "    baro_df = pd.read_csv(baro_file)\n",
    "    \n",
    "    imu_df = pd.read_csv(imu_file)\n",
    "    \n",
    "    imu_df['baro'] = baro_df['baro']\n",
    "        \n",
    "    return imu_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa026df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list = []\n",
    "\n",
    "# for velocity in velocities:\n",
    "#     for texture in texture_names:\n",
    "#         df = load_and_merge_data(root_folder, velocity, texture).iloc[0:10000]\n",
    "#         if df.empty:\n",
    "#             print(f\"No data for Velocity: {velocity} mm/s, Texture: {texture}. Skipping...\")\n",
    "#             continue\n",
    "#         df_list.append(df)\n",
    "\n",
    "# merged_df = pd.concat(df_list)\n",
    "\n",
    "sliding_window_size=500\n",
    "for velocity in velocities:\n",
    "    for texture in texture_names:\n",
    "        merged_df = load_and_merge_data(root_folder, velocity, texture)\n",
    "        if merged_df.empty:\n",
    "            print(f\"No data for Velocity: {velocity} mm/s, Texture: {texture}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        total_samples = len(merged_df)\n",
    "\n",
    "        num_chunks = total_samples // sliding_window_size\n",
    "\n",
    "        truncated_df = merged_df.iloc[:num_chunks * sliding_window_size]\n",
    "\n",
    "        averaged_df = truncated_df.values.reshape(num_chunks, sliding_window_size, merged_df.shape[1]).mean(axis=1)\n",
    "\n",
    "        averaged_df = pd.DataFrame(averaged_df, columns=merged_df.columns)\n",
    "\n",
    "        df_list.append(averaged_df)\n",
    "\n",
    "final_merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a77188d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_merged_df[['baro','imu_ax', 'imu_ay', 'imu_az','imu_gx', 'imu_gy', 'imu_gz','imu_mx', 'imu_my', 'imu_mz']].values\n",
    "y = final_merged_df['Texture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145d798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples collected: 90665\n",
      "Feature vector size: 10\n",
      "Unique textures: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Total samples collected: {X.shape[0]}\")\n",
    "print(f\"Feature vector size: {X.shape[1]}\")\n",
    "print(f\"Unique textures: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f4fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded texture labels: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "texture_classes = label_encoder.classes_\n",
    "num_classes = len(texture_classes)\n",
    "print(\"\\nEncoded texture labels:\", texture_classes)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de985b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# def count_classes(y, label_encoder):\n",
    "#     unique, counts = np.unique(y, return_counts=True)\n",
    "#     class_counts = dict(zip(label_encoder.inverse_transform(unique), counts))\n",
    "#     return class_counts\n",
    "\n",
    "# train_class_counts = count_classes(y_train, label_encoder)\n",
    "# test_class_counts = count_classes(y_test, label_encoder)\n",
    "\n",
    "# print(\"Training Set Class Distribution:\")\n",
    "# print(train_class_counts)\n",
    "# print(\"\\nTest Set Class Distribution:\")\n",
    "# print(test_class_counts)\n",
    "\n",
    "def poisson_encoding(features, num_steps, device='cpu'):\n",
    "\n",
    "    features_repeated = features.unsqueeze(1).repeat(1, num_steps, 1)\n",
    "    \n",
    "    rand_vals = torch.rand_like(features_repeated, device=device)\n",
    "    \n",
    "    spikes = (rand_vals < features_repeated).float()\n",
    "    \n",
    "    return spikes\n",
    "\n",
    "def encode_to_spike_train(features, num_steps, device='cpu'):\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32, device=device)\n",
    "\n",
    "    spike_trains = poisson_encoding(features_tensor, num_steps=num_steps, device=device)\n",
    "    \n",
    "    return spike_trains\n",
    "\n",
    "num_steps = 100\n",
    "train_spike_trains = encode_to_spike_train(X_train, num_steps)\n",
    "test_spike_trains = encode_to_spike_train(X_test, num_steps)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(train_spike_trains, y_train_tensor)\n",
    "test_dataset = TensorDataset(test_spike_trains, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33b2642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:31:55.171546Z",
     "iopub.status.busy": "2023-01-16T21:31:55.171181Z",
     "iopub.status.idle": "2023-01-16T21:31:55.768948Z",
     "shell.execute_reply": "2023-01-16T21:31:55.767637Z"
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1673831876642,
     "user": {
      "displayName": "Vinicius Prado da Fonseca",
      "userId": "07076031591394214642"
     },
     "user_tz": 210
    },
    "id": "-OpBEX94Jln0",
    "outputId": "60d65592-0eee-462c-b3b1-082af0be4245",
    "papermill": {
     "duration": 0.604373,
     "end_time": "2023-01-16T21:31:55.772089",
     "exception": false,
     "start_time": "2023-01-16T21:31:55.167716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.8253, Accuracy: 32.48%\n",
      "Epoch 2/20, Loss: 1.6706, Accuracy: 36.58%\n",
      "Epoch 3/20, Loss: 1.6432, Accuracy: 37.48%\n",
      "Epoch 4/20, Loss: 1.6254, Accuracy: 37.91%\n",
      "Epoch 5/20, Loss: 1.6129, Accuracy: 38.30%\n",
      "Epoch 6/20, Loss: 1.6011, Accuracy: 38.73%\n",
      "Epoch 7/20, Loss: 1.5874, Accuracy: 39.12%\n",
      "Epoch 8/20, Loss: 1.5837, Accuracy: 39.30%\n",
      "Epoch 9/20, Loss: 1.5747, Accuracy: 39.55%\n",
      "Epoch 10/20, Loss: 1.5726, Accuracy: 39.51%\n",
      "Epoch 11/20, Loss: 1.5627, Accuracy: 39.92%\n",
      "Epoch 12/20, Loss: 1.5605, Accuracy: 39.94%\n",
      "Epoch 13/20, Loss: 1.5498, Accuracy: 40.32%\n",
      "Epoch 14/20, Loss: 1.5459, Accuracy: 40.46%\n",
      "Epoch 15/20, Loss: 1.5425, Accuracy: 40.50%\n",
      "Epoch 16/20, Loss: 1.5398, Accuracy: 40.74%\n",
      "Epoch 17/20, Loss: 1.5347, Accuracy: 40.84%\n",
      "Epoch 18/20, Loss: 1.5345, Accuracy: 40.86%\n",
      "Epoch 19/20, Loss: 1.5288, Accuracy: 40.99%\n",
      "Epoch 20/20, Loss: 1.5279, Accuracy: 41.03%\n",
      "Test Accuracy: 40.71%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_inputs = X_train.shape[1]\n",
    "num_hidden = 100\n",
    "num_outputs = num_classes\n",
    "beta = 0.9\n",
    "\n",
    "class SNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        spk_rec = []\n",
    "        for step in range(x.size(1)):\n",
    "            input_step = x[:, step, :]\n",
    "            cur1 = self.fc1(input_step)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk_rec.append(spk3)\n",
    "        \n",
    "        out_spikes = torch.stack(spk_rec, dim=0)\n",
    "        return out_spikes\n",
    "    \n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif3 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for step in range(x.size(1)):\n",
    "            input_step = x[:, step, :]\n",
    "            cur1 = self.fc1(input_step)\n",
    "            spk1 = self.lif1(cur1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2 = self.lif2(cur2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            out = self.lif3(cur3)\n",
    "        \n",
    "        return out\n",
    "\n",
    "net = SNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "def forward_pass(net, data):\n",
    "\n",
    "    spk_rec = net(data)\n",
    "    return spk_rec\n",
    "\n",
    "def train_model(net, train_loader, optimizer, criterion, num_epochs=20):\n",
    "\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for data, targets in train_loader:\n",
    "            data = data.float()\n",
    "            targets = targets.long()\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            spk_sum = spk_rec.sum(dim=0)\n",
    "            loss = criterion(spk_sum, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            _, predicted = spk_sum.max(1)\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "        acc = total_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss / len(train_loader):.4f}, Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "def evaluate_model(net, test_loader):\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.float()\n",
    "            targets = targets.long()\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            spk_sum = spk_rec.sum(dim=0)\n",
    "            _, predicted = spk_sum.max(1)\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "    acc = total_correct / total_samples\n",
    "    print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "num_epochs = 20\n",
    "train_model(net, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "evaluate_model(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb361b9b",
   "metadata": {},
   "source": [
    "Temporal coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6abcdffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples collected: 90665\n",
      "Feature vector size: 10\n",
      "Unique textures: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
      "\n",
      "Encoded texture labels: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
      "Epoch 1/20, Loss: 2.4315, Accuracy: 11.57%\n",
      "Epoch 2/20, Loss: 2.0260, Accuracy: 29.30%\n",
      "Epoch 3/20, Loss: 1.7644, Accuracy: 37.56%\n",
      "Epoch 4/20, Loss: 1.6160, Accuracy: 42.53%\n",
      "Epoch 5/20, Loss: 1.5509, Accuracy: 44.78%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 257\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m    256\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m--> 257\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    260\u001b[0m evaluate_model(net, test_loader)\n",
      "Cell \u001b[0;32mIn[21], line 206\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(net, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m    203\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m spk_rec \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Decode output spikes by summing over time\u001b[39;00m\n\u001b[1;32m    209\u001b[0m spk_sum \u001b[38;5;241m=\u001b[39m spk_rec\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 189\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(net, data)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(net, data):\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    Forward pass through the network.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     spk_rec \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spk_rec\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 169\u001b[0m, in \u001b[0;36mTemporalSNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m input_step \u001b[38;5;241m=\u001b[39m x[:, step, :]\n\u001b[1;32m    168\u001b[0m cur1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(input_step)\n\u001b[0;32m--> 169\u001b[0m spk1, mem1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlif1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m cur2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(spk1)\n\u001b[1;32m    171\u001b[0m spk2, mem2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif2(cur2, mem2)\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/snntorch/_neurons/leaky.py:220\u001b[0m, in \u001b[0;36mLeaky.forward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    216\u001b[0m     spk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfire_inhibition(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\n\u001b[1;32m    218\u001b[0m     )  \u001b[38;5;66;03m# batch_size\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     spk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_delay:\n\u001b[1;32m    223\u001b[0m     do_reset \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    224\u001b[0m         spk \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraded_spikes_factor \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset\n\u001b[1;32m    225\u001b[0m     )  \u001b[38;5;66;03m# avoid double reset\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/snntorch/_neurons/neurons.py:81\u001b[0m, in \u001b[0;36mSpikingNeuron.fire\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     78\u001b[0m     mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_quant(mem)\n\u001b[1;32m     80\u001b[0m mem_shift \u001b[38;5;241m=\u001b[39m mem \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\n\u001b[0;32m---> 81\u001b[0m spk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspike_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmem_shift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m spk \u001b[38;5;241m=\u001b[39m spk \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraded_spikes_factor\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spk\n",
      "File \u001b[0;32m~/miniconda3/envs/spatial/lib/python3.10/site-packages/snntorch/surrogate.py:210\u001b[0m, in \u001b[0;36matan.<locals>.inner\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"ArcTan surrogate gradient enclosed with a parameterized slope.\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m alpha \u001b[38;5;241m=\u001b[39m alpha\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(x):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ATan\u001b[38;5;241m.\u001b[39mapply(x, alpha)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the root folder containing the dataset\n",
    "root_folder = \"./tactile_dataset/\"\n",
    "\n",
    "# Define velocities and texture names\n",
    "velocities = [30]\n",
    "num_textures = 12\n",
    "texture_names = [f\"texture_{i:02d}\" for i in range(1, num_textures + 1)]\n",
    "\n",
    "def load_and_merge_data(root, velocity, texture):\n",
    "    \"\"\"\n",
    "    Load and merge barometric and IMU data for a specific velocity and texture.\n",
    "    \"\"\"\n",
    "    velocity_folder = os.path.join(root, f\"pickles_{velocity}\")\n",
    "    texture_folder = os.path.join(velocity_folder, texture)\n",
    "    \n",
    "    baro_file = os.path.join(texture_folder, \"full_baro.csv\")\n",
    "    imu_file = os.path.join(texture_folder, \"full_imu.csv\")\n",
    "    \n",
    "    baro_df = pd.read_csv(baro_file)\n",
    "    imu_df = pd.read_csv(imu_file)\n",
    "    \n",
    "    # Merge barometric data into IMU dataframe\n",
    "    imu_df['baro'] = baro_df['baro']\n",
    "        \n",
    "    return imu_df\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# Parameters for sliding window\n",
    "sliding_window_size = 500\n",
    "\n",
    "# Load and preprocess data\n",
    "for velocity in velocities:\n",
    "    for texture in texture_names:\n",
    "        merged_df = load_and_merge_data(root_folder, velocity, texture)\n",
    "        if merged_df.empty:\n",
    "            print(f\"No data for Velocity: {velocity} mm/s, Texture: {texture}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        total_samples = len(merged_df)\n",
    "        num_chunks = total_samples // sliding_window_size\n",
    "        truncated_df = merged_df.iloc[:num_chunks * sliding_window_size]\n",
    "        averaged_df = truncated_df.values.reshape(num_chunks, sliding_window_size, merged_df.shape[1]).mean(axis=1)\n",
    "        averaged_df = pd.DataFrame(averaged_df, columns=merged_df.columns)\n",
    "        df_list.append(averaged_df)\n",
    "\n",
    "final_merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Feature extraction\n",
    "X = final_merged_df[['baro','imu_ax', 'imu_ay', 'imu_az','imu_gx', 'imu_gy', 'imu_gz','imu_mx', 'imu_my', 'imu_mz']].values\n",
    "y = final_merged_df['Texture']\n",
    "\n",
    "print(f\"Total samples collected: {X.shape[0]}\")\n",
    "print(f\"Feature vector size: {X.shape[1]}\")\n",
    "print(f\"Unique textures: {np.unique(y)}\")\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "texture_classes = label_encoder.classes_\n",
    "num_classes = len(texture_classes)\n",
    "print(\"\\nEncoded texture labels:\", texture_classes)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "def temporal_encoding(features, num_steps, device='cpu'):\n",
    "    \"\"\"\n",
    "    Temporal encoding where each feature fires a single spike at a time step\n",
    "    inversely proportional to its value (higher value -> earlier spike).\n",
    "    \"\"\"\n",
    "    # Convert features to tensor if not already\n",
    "    if not isinstance(features, torch.Tensor):\n",
    "        features = torch.tensor(features, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Ensure features are scaled between 0 and 1\n",
    "    features = torch.clamp(features, 0, 1)\n",
    "    \n",
    "    # Calculate spike times: higher feature value -> earlier spike\n",
    "    spike_times = torch.round((1.0 - features) * (num_steps - 1)).long()\n",
    "    spike_times = torch.clamp(spike_times, 0, num_steps - 1)\n",
    "    \n",
    "    batch_size, num_features = spike_times.size()\n",
    "    spikes = torch.zeros(batch_size, num_steps, num_features, device=device)\n",
    "    \n",
    "    # Vectorized assignment of spikes\n",
    "    batch_indices = torch.arange(batch_size, device=device).unsqueeze(1).repeat(1, num_features)\n",
    "    feature_indices = torch.arange(num_features, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
    "    spikes[batch_indices, spike_times, feature_indices] = 1.0\n",
    "    \n",
    "    return spikes\n",
    "\n",
    "def encode_to_spike_train_temporal(features, num_steps, device='cpu'):\n",
    "    \"\"\"\n",
    "    Wrapper for temporal encoding.\n",
    "    \"\"\"\n",
    "    return temporal_encoding(features, num_steps=num_steps, device=device)\n",
    "\n",
    "# Define number of time steps for temporal encoding\n",
    "num_steps = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Encode training and testing data\n",
    "train_spike_trains = encode_to_spike_train_temporal(X_train, num_steps, device=device)\n",
    "test_spike_trains = encode_to_spike_train_temporal(X_test, num_steps, device=device)\n",
    "\n",
    "# Convert labels to tensors\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_spike_trains, y_train_tensor)\n",
    "test_dataset = TensorDataset(test_spike_trains, y_test_tensor)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define network parameters\n",
    "num_inputs = X_train.shape[1]\n",
    "num_hidden = 100\n",
    "num_outputs = num_classes\n",
    "beta = 0.9  # Leaky parameter\n",
    "\n",
    "class TemporalSNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemporalSNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize membrane potentials\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        spk_rec = []\n",
    "        for step in range(x.size(1)):\n",
    "            input_step = x[:, step, :]\n",
    "            cur1 = self.fc1(input_step)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk_rec.append(spk3)\n",
    "        \n",
    "        # Stack spike recordings across time\n",
    "        out_spikes = torch.stack(spk_rec, dim=0)\n",
    "        return out_spikes\n",
    "\n",
    "# Initialize the network, loss function, and optimizer\n",
    "net = TemporalSNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "def forward_pass(net, data):\n",
    "    \"\"\"\n",
    "    Forward pass through the network.\n",
    "    \"\"\"\n",
    "    spk_rec = net(data)\n",
    "    return spk_rec\n",
    "\n",
    "def train_model(net, train_loader, optimizer, criterion, num_epochs=20):\n",
    "    \"\"\"\n",
    "    Train the SNN model.\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for data, targets in train_loader:\n",
    "            data = data.float().to(device)\n",
    "            targets = targets.long().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            \n",
    "            # Decode output spikes by summing over time\n",
    "            spk_sum = spk_rec.sum(dim=0)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(spk_sum, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = spk_sum.max(1)\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "        \n",
    "        acc = total_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss / len(train_loader):.4f}, Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "def evaluate_model(net, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the SNN model on the test set.\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.float().to(device)\n",
    "            targets = targets.long().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            \n",
    "            # Decode output spikes by summing over time\n",
    "            spk_sum = spk_rec.sum(dim=0)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = spk_sum.max(1)\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "    \n",
    "    acc = total_correct / total_samples\n",
    "    print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 20\n",
    "train_model(net, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(net, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b16022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.99%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.144066,
   "end_time": "2023-01-16T21:31:56.500051",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-16T21:31:46.355985",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
