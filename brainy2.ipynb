{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     imu_ax    imu_ay    imu_az    imu_gx    imu_gy    imu_gz    imu_mx  \\\n",
      "0 -0.714646 -3.751385  8.952035  0.271843  0.887275  0.235063 -0.142849   \n",
      "1  1.325862 -3.764498  8.800300 -0.303642  0.904468  0.343564  0.270401   \n",
      "2  2.542223 -3.111482  8.754128 -0.245584  0.441520  0.233173  0.519580   \n",
      "3  2.803708 -2.582370  8.868835 -0.337755  0.003374  0.098259  0.508302   \n",
      "4  3.854054 -2.298121  8.681546 -0.108013  0.197704  0.046265  0.777799   \n",
      "\n",
      "     imu_my    imu_mz  Texture     baro  \n",
      "0 -0.747876  1.757683      1.0  173.848  \n",
      "1 -0.767744  1.794762      1.0  194.202  \n",
      "2 -0.632350  1.753249      1.0  196.912  \n",
      "3 -0.499855  1.791200      1.0  196.594  \n",
      "4 -0.461740  1.769799      1.0  200.554  \n"
     ]
    }
   ],
   "source": [
    "root_folder = \"./tactile_dataset/\"\n",
    "file_name = \"final_merged_df_sw500.csv\"\n",
    "\n",
    "df = pd.read_csv(root_folder + file_name)\n",
    "print(df.head())\n",
    "\n",
    "y = df['Texture']\n",
    "X = df.drop(['Texture'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def encode_target(y_train, y_test):\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.transform(y_test)\n",
    "    return y_train, y_test\n",
    "\n",
    "def encode_target_onehot(y_train, y_test):\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_test = y_test.values.reshape(-1, 1)\n",
    "    y_train = onehot_encoder.fit_transform(y_train)\n",
    "    y_test = onehot_encoder.transform(y_test)\n",
    "    return y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_thresholds = None\n",
    "def poisson_encoding(features, num_steps):\n",
    "    features_repeated = features.unsqueeze(1).repeat(1, num_steps)\n",
    "    rand_vals = torch.rand_like(features_repeated)\n",
    "    spikes = (rand_vals < features_repeated).float()\n",
    "    return spikes\n",
    "\n",
    "def temporal_contrast_encode(features, num_steps, delta_thresholds):\n",
    "    diffs = torch.diff(features, dim=0, prepend=features[:1])\n",
    "    spikes = (torch.abs(diffs) > delta_thresholds).float()\n",
    "    spikes = spikes.unsqueeze(1).repeat(1, num_steps, 1)\n",
    "    return spikes\n",
    "\n",
    "def get_delta_thresholds(features, k):\n",
    "    diffs = torch.diff(features, dim=0, prepend=features[:1])\n",
    "    return (torch.std(diffs, dim=0) * k)\n",
    "\n",
    "def encode_to_spike_train(features, num_steps=50, k=2, delta_thresholds=None):\n",
    "    features_for_rate_coding = features[:, 9]\n",
    "    features_for_temporal_contrast = features[:, :9]\n",
    "    if delta_thresholds is None:\n",
    "        delta_thresholds = get_delta_thresholds(features_for_temporal_contrast, k)\n",
    "    print(delta_thresholds)\n",
    "    spikes_rate_coding = poisson_encoding(features_for_rate_coding, num_steps)\n",
    "    spikes_temporal_contrast = temporal_contrast_encode(features_for_temporal_contrast, num_steps, delta_thresholds)\n",
    "    spikes_rate_coding = spikes_rate_coding.unsqueeze(-1)\n",
    "\n",
    "    return torch.cat([spikes_rate_coding, spikes_temporal_contrast], dim=-1), delta_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2160, 0.2852, 0.1739, 0.1218, 0.1318, 0.1326, 0.2130, 0.2845, 0.1549])\n",
      "tensor([0.2160, 0.2852, 0.1739, 0.1218, 0.1318, 0.1326, 0.2130, 0.2845, 0.1549])\n"
     ]
    }
   ],
   "source": [
    "delta_thresholds = None\n",
    "num_steps = 100\n",
    "k = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_test = scale_data(X_train, X_test)\n",
    "y_train, y_test = encode_target(y_train, y_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_train, delta_thresholds = encode_to_spike_train(X_train, num_steps=num_steps, k=k)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "X_test = encode_to_spike_train(X_test, num_steps=num_steps, k=k, delta_thresholds=delta_thresholds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72532])\n",
      "tensor([0, 7, 9, 2, 5])\n",
      "torch.Size([72532, 100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train[:5])\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "\n",
    "num_inputs = X_train.shape[2]\n",
    "num_outputs = 12\n",
    "num_hidden = 100\n",
    "beta = 0.9\n",
    "\n",
    "class SNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        batch_size, num_steps, _ = x.shape\n",
    "        output_spikes = torch.zeros(batch_size, num_outputs).to(device)\n",
    "        for step in range(x.size(1)):\n",
    "            input_step = x[:, step, :]\n",
    "            cur1 = self.fc1(input_step)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            output_spikes += spk3\n",
    "        return output_spikes / num_steps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        total_correct = 0.0\n",
    "        start_time = time.time()\n",
    "        for _, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(dim=-1) == labels.argmax(dim=-1)).float().mean()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {(total_correct / len(train_loader))*100:.2f}, Time: {elapsed_time:.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-3)\n",
    "\n",
    "train_model(net, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
